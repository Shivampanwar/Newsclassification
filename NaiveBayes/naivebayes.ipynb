{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import  CountVectorizer,TfidfTransformer,TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "import time \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv('../Data/training.csv')\n",
    "test_dataframe = pd.read_csv('../Data/testing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps followed\n",
    "Firstly, we will clean our data then we need to convert our cleaned text data into TFIDF vectors and then we will use those TFIDF vector as input to classifier. We will first find optimal parameters for TFIDF and then using those paramaters, we will find best hyperparameters for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe=train_dataframe[['Category','Article']]\n",
    "test_dataframe=test_dataframe[['Category','Article']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>A dash of stand up comedy, lots of improvisat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Actor Tamannaah Bhatia is excited to have sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>They say you never forget your first. Tri-city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>It was in the year 1968 when the Beatles were...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                            Article\n",
       "0  Entertainment   A dash of stand up comedy, lots of improvisat...\n",
       "1  Entertainment   Actor Tamannaah Bhatia is excited to have sig...\n",
       "2  Entertainment  They say you never forget your first. Tri-city...\n",
       "3  Entertainment   It was in the year 1968 when the Beatles were..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer() #For words Lemmatization\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TokenizeText(text):\n",
    "    ''' \n",
    "     Tokenizes text by removing various stopwords and lemmatizing them\n",
    "    '''\n",
    "    text=str(text)\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^A-Za-z0-9\\s]+', '', text)\n",
    "    word_list=word_tokenize(text)\n",
    "    word_list_final=[]\n",
    "    for word in word_list:\n",
    "        if word not in stop_words:\n",
    "            word_list_final.append(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(word_list_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.7 s, sys: 60.3 ms, total: 6.76 s\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataframe.Article = train_dataframe.Article.apply(TokenizeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.Article = test_dataframe.Article.apply(TokenizeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>dash stand comedy lot improvisation ton audien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>actor tamannaah bhatia excited signed acclaime...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                            Article\n",
       "0  Entertainment  dash stand comedy lot improvisation ton audien...\n",
       "1  Entertainment  actor tamannaah bhatia excited signed acclaime..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimal TFIDF paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tf= TfidfVectorizer()\n",
    "temp_tf.fit(train_dataframe.Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_tf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "...     ('vect', TfidfVectorizer()),\n",
    "...     ('tfidf', TfidfTransformer()),\n",
    "...     ('clf', MultinomialNB()),\n",
    "... ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (1000, 10000, 20000, 40000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__max_df': (0.5, 0.75, 1.0), 'vect__max_features': (1000, 10000, 20000, 40000), 'vect__ngram_range': ((1, 1), (1, 2)), 'tfidf__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/miniconda3/envs/metal/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_...\n",
       "                                                         use_idf=True)),\n",
       "                                       ('clf',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'tfidf__use_idf': (True, False),\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__max_features': (1000, 10000, 20000, 40000),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "print(\"parameters: {}\".format(parameters))\n",
    "t0 = time.time()\n",
    "grid_search.fit(train_dataframe.Article,train_dataframe.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8069686411149826"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.75,\n",
       "                                 max_features=40000, min_df=1,\n",
       "                                 ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we have found the best parameters for the TFIDF. We will now  find best parameeters for Naivebayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer=grid_search.best_estimator_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we will combine train and test data to obtain merged Articles. Then we would fit above found TFIDf on given articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.75,\n",
       "                max_features=40000, min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer.fit(pd.concat([train_dataframe,test_dataframe])['Article'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tfidfvectorizer.transform(train_dataframe['Article'].values)\n",
    "x_test=tfidfvectorizer.transform(test_dataframe['Article'].values)\n",
    "y_train=train_dataframe['Category'].values\n",
    "y_test=test_dataframe['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1435, 40000), (354, 40000))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/miniconda3/envs/metal/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "CPU times: user 75.5 ms, sys: 7.43 ms, total: 82.9 ms\n",
      "Wall time: 890 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.1, 0.5, 1, 1.5, 2, 5],\n",
       "                         'fit_prior': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'alpha':[0.1,0.5,1,1.5,2,5],'fit_prior':[True,False]}\n",
    "bayes=MultinomialNB()\n",
    "clf = GridSearchCV(bayes, parameters,verbose=1,n_jobs=-1,scoring='accuracy')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104529616724738"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramters for naive bayes is MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print (\"Best paramters for naive bayes is {}\".format(str(clf.best_estimator_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_classifier=clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 ms, sys: 0 ns, total: 34.2 ms\n",
      "Wall time: 73.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### fitting final\n",
    "bayesian_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=bayesian_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive bayes is 0.807909604519774\n"
     ]
    }
   ],
   "source": [
    "##Accuracy \n",
    "print (\"Accuracy of Multinomial Naive bayes is {}\".format(str(accuracy_score(y_test,predicted))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Business &amp; Economy</th>\n",
       "      <th>Education &amp; Career</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Food &amp; Health</th>\n",
       "      <th>International</th>\n",
       "      <th>Others</th>\n",
       "      <th>Politics &amp; Governance</th>\n",
       "      <th>Science &amp; Technology</th>\n",
       "      <th>Sports</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business &amp; Economy</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education &amp; Career</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food &amp; Health</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politics &amp; Governance</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science &amp; Technology</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted              Business & Economy  Education & Career  Entertainment  \\\n",
       "Actual                                                                         \n",
       "Business & Economy                     36                   0              0   \n",
       "Education & Career                      0                  37              2   \n",
       "Entertainment                           0                   1             37   \n",
       "Food & Health                           0                   2              1   \n",
       "International                           1                   1              3   \n",
       "Others                                  1                   4              5   \n",
       "Politics & Governance                   2                   1              0   \n",
       "Science & Technology                    0                   5              4   \n",
       "Sports                                  0                   0              0   \n",
       "\n",
       "Predicted              Food & Health  International  Others  \\\n",
       "Actual                                                        \n",
       "Business & Economy                 1              0       1   \n",
       "Education & Career                 0              0       0   \n",
       "Entertainment                      0              0       1   \n",
       "Food & Health                     32              0       0   \n",
       "International                      0             32       3   \n",
       "Others                             1              3      17   \n",
       "Politics & Governance              0              1       3   \n",
       "Science & Technology               3              0       0   \n",
       "Sports                             0              0       0   \n",
       "\n",
       "Predicted              Politics & Governance  Science & Technology  Sports  \n",
       "Actual                                                                      \n",
       "Business & Economy                         1                     1       0  \n",
       "Education & Career                         0                     1       0  \n",
       "Entertainment                              0                     1       0  \n",
       "Food & Health                              0                     5       0  \n",
       "International                              0                     0       0  \n",
       "Others                                     6                     3       0  \n",
       "Politics & Governance                     27                     0       0  \n",
       "Science & Technology                       0                    28       0  \n",
       "Sports                                     0                     0      40  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### confusion matrix\n",
    "pd.crosstab(y_test, predicted, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predicted, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business &amp; Economy</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education &amp; Career</th>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food &amp; Health</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politics &amp; Governance</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>34.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science &amp; Technology</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.80791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.809205</td>\n",
       "      <td>0.807680</td>\n",
       "      <td>0.801874</td>\n",
       "      <td>354.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.809461</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.802005</td>\n",
       "      <td>354.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score    support\n",
       "Business & Economy      0.900000  0.900000  0.900000   40.00000\n",
       "Education & Career      0.725490  0.925000  0.813187   40.00000\n",
       "Entertainment           0.711538  0.925000  0.804348   40.00000\n",
       "Food & Health           0.864865  0.800000  0.831169   40.00000\n",
       "International           0.888889  0.800000  0.842105   40.00000\n",
       "Others                  0.680000  0.425000  0.523077   40.00000\n",
       "Politics & Governance   0.794118  0.794118  0.794118   34.00000\n",
       "Science & Technology    0.717949  0.700000  0.708861   40.00000\n",
       "Sports                  1.000000  1.000000  1.000000   40.00000\n",
       "accuracy                0.807910  0.807910  0.807910    0.80791\n",
       "macro avg               0.809205  0.807680  0.801874  354.00000\n",
       "weighted avg            0.809461  0.807910  0.802005  354.00000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal] *",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
