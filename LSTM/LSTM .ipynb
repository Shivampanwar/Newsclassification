{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, AveragePooling1D, GlobalAvgPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.models import  Sequential\n",
    "from keras.layers import Dense,Flatten,Embedding,LSTM,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1435, 4)\n",
      "Test shape :  (354, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../Data/training.csv\")\n",
    "test_df = pd.read_csv(\"../Data/testing.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['Category','Article']]\n",
    "test_df = test_df[['Category','Article']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>A dash of stand up comedy, lots of improvisat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Actor Tamannaah Bhatia is excited to have sig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                            Article\n",
       "0  Entertainment   A dash of stand up comedy, lots of improvisat...\n",
       "1  Entertainment   Actor Tamannaah Bhatia is excited to have sig..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_df.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "def TokenizeText(text):\n",
    "    ''' \n",
    "     Tokenizes text by removing various stopwords and lemmatizing them\n",
    "    '''\n",
    "    text=str(text)\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^A-Za-z0-9\\s]+', '', text)\n",
    "    word_list=word_tokenize(text)\n",
    "    word_list_final=[]\n",
    "    for word in word_list:\n",
    "        if word not in stop_words:\n",
    "            word_list_final.append((word))\n",
    "    return \" \".join(word_list_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Article =  train_df.Article.apply(TokenizeText)\n",
    "test_df.Article = test_df.Article.apply(TokenizeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2020)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 200 # max number of words in a article to use\n",
    "\n",
    "# ## fill up the missing values\n",
    "train_X = train_df[\"Article\"].values\n",
    "val_X = val_df[\"Article\"].values\n",
    "test_X = test_df[\"Article\"].values\n",
    "\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features,)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['Category'].values\n",
    "val_y = val_df['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1287, 200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(EMBEDDING_FILE)\n",
    "for count,line in enumerate(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        pass\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_features:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_categories = train_df.Category.nunique()\n",
    "num_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=to_categorical(le.transform(train_y))\n",
    "val_y= to_categorical(le.transform(val_y))\n",
    "test_y= to_categorical(le.transform(test_df.Category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 200, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200, 64)           93440     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 153       \n",
      "=================================================================\n",
      "Total params: 30,094,633\n",
      "Trainable params: 15,094,633\n",
      "Non-trainable params: 15,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "# x = LSTM(64, return_sequences=True)(x)\n",
    "\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(num_categories, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1287 samples, validate on 143 samples\n",
      "Epoch 1/500\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 1.9367 - acc: 0.3535 - val_loss: 1.6112 - val_acc: 0.4545\n",
      "Epoch 2/500\n",
      "1287/1287 [==============================] - 32s 25ms/step - loss: 1.3111 - acc: 0.5758 - val_loss: 1.1979 - val_acc: 0.6224\n",
      "Epoch 3/500\n",
      "1287/1287 [==============================] - 37s 29ms/step - loss: 0.9352 - acc: 0.7405 - val_loss: 1.0192 - val_acc: 0.6923\n",
      "Epoch 4/500\n",
      "1287/1287 [==============================] - 33s 26ms/step - loss: 0.6395 - acc: 0.8438 - val_loss: 0.9229 - val_acc: 0.7273\n",
      "Epoch 5/500\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.4599 - acc: 0.8772 - val_loss: 0.8335 - val_acc: 0.7622\n",
      "Epoch 6/500\n",
      "1287/1287 [==============================] - 31s 24ms/step - loss: 0.3352 - acc: 0.9184 - val_loss: 0.8706 - val_acc: 0.7762\n",
      "Epoch 7/500\n",
      "1287/1287 [==============================] - 24s 18ms/step - loss: 0.2462 - acc: 0.9549 - val_loss: 0.8332 - val_acc: 0.7552\n",
      "Epoch 8/500\n",
      "1287/1287 [==============================] - 28s 22ms/step - loss: 0.1582 - acc: 0.9767 - val_loss: 1.0066 - val_acc: 0.7622\n",
      "Epoch 9/500\n",
      "1287/1287 [==============================] - 26s 21ms/step - loss: 0.1244 - acc: 0.9806 - val_loss: 0.9768 - val_acc: 0.7762\n",
      "Epoch 10/500\n",
      "1287/1287 [==============================] - 23s 18ms/step - loss: 0.1077 - acc: 0.9806 - val_loss: 1.0501 - val_acc: 0.7343\n",
      "Epoch 11/500\n",
      "1287/1287 [==============================] - 22s 17ms/step - loss: 0.0824 - acc: 0.9868 - val_loss: 1.2133 - val_acc: 0.7343\n",
      "Epoch 12/500\n",
      "1287/1287 [==============================] - 23s 18ms/step - loss: 0.0812 - acc: 0.9821 - val_loss: 1.1847 - val_acc: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e2b8b5390>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=32, epochs=500, callbacks=callbacks,validation_data=(val_X, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7552447552447552"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(val_y,axis=1),np.argmax(model.predict(val_X),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test_target  = test_df.Category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = le.inverse_transform(np.argmax(model.predict(test_X),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest is 0.7507082152974505\n"
     ]
    }
   ],
   "source": [
    "#Accuracy \n",
    "print (\"Accuracy of random forest is {}\".format(str(accuracy_score(actual_test_target,predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 200, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200, 64)           93440     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 9)                 153       \n",
      "=================================================================\n",
      "Total params: 30,094,633\n",
      "Trainable params: 15,094,633\n",
      "Non-trainable params: 15,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "# x = LSTM(64, return_sequences=True)(x)\n",
    "\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(num_categories, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1430/1430 [==============================] - 28s 19ms/step - loss: 1.8840 - acc: 0.3098\n",
      "Epoch 2/7\n",
      "1430/1430 [==============================] - 27s 19ms/step - loss: 1.2891 - acc: 0.5706\n",
      "Epoch 3/7\n",
      "1430/1430 [==============================] - 33s 23ms/step - loss: 0.8756 - acc: 0.7580\n",
      "Epoch 4/7\n",
      "1430/1430 [==============================] - 29s 20ms/step - loss: 0.5917 - acc: 0.8469\n",
      "Epoch 5/7\n",
      "1430/1430 [==============================] - 27s 19ms/step - loss: 0.4693 - acc: 0.8748\n",
      "Epoch 6/7\n",
      "1430/1430 [==============================] - 26s 18ms/step - loss: 0.3288 - acc: 0.9287\n",
      "Epoch 7/7\n",
      "1430/1430 [==============================] - 25s 17ms/step - loss: 0.2123 - acc: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e024cbbe0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.vstack([train_X,val_X]), np.vstack([train_y,val_y]), batch_size=32, epochs=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test_target  = test_df.Category.values\n",
    "predictions = le.inverse_transform(np.argmax(model.predict(test_X),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LSTM is 0.7563739376770539\n"
     ]
    }
   ],
   "source": [
    "#Accuracy \n",
    "print (\"Accuracy of LSTM is {}\".format(str(accuracy_score(actual_test_target,predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Business &amp; Economy</th>\n",
       "      <th>Education &amp; Career</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Food &amp; Health</th>\n",
       "      <th>International</th>\n",
       "      <th>Others</th>\n",
       "      <th>Politics &amp; Governance</th>\n",
       "      <th>Science &amp; Technology</th>\n",
       "      <th>Sports</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business &amp; Economy</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education &amp; Career</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food &amp; Health</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politics &amp; Governance</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science &amp; Technology</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted              Business & Economy  Education & Career  Entertainment  \\\n",
       "Actual                                                                         \n",
       "Business & Economy                     35                   1              0   \n",
       "Education & Career                      0                  33              2   \n",
       "Entertainment                           0                   2             35   \n",
       "Food & Health                           0                   2              1   \n",
       "International                           0                   1              0   \n",
       "Others                                  3                   4              3   \n",
       "Politics & Governance                   0                   1              0   \n",
       "Science & Technology                    0                   2              3   \n",
       "Sports                                  0                   0              0   \n",
       "\n",
       "Predicted              Food & Health  International  Others  \\\n",
       "Actual                                                        \n",
       "Business & Economy                 0              0       0   \n",
       "Education & Career                 1              0       1   \n",
       "Entertainment                      0              0       2   \n",
       "Food & Health                     27              1       3   \n",
       "International                      0             31       6   \n",
       "Others                             0              3      16   \n",
       "Politics & Governance              0              7       6   \n",
       "Science & Technology               2              0       2   \n",
       "Sports                             0              0       0   \n",
       "\n",
       "Predicted              Politics & Governance  Science & Technology  Sports  \n",
       "Actual                                                                      \n",
       "Business & Economy                         1                     3       0  \n",
       "Education & Career                         0                     3       0  \n",
       "Entertainment                              0                     0       0  \n",
       "Food & Health                              0                     4       2  \n",
       "International                              2                     0       0  \n",
       "Others                                     7                     4       0  \n",
       "Politics & Governance                     20                     0       0  \n",
       "Science & Technology                       1                    30       0  \n",
       "Sports                                     0                     0      40  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### confusion matrix\n",
    "pd.crosstab(actual_test_target, predictions, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(actual_test_target, predictions, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business &amp; Economy</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education &amp; Career</th>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food &amp; Health</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International</th>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politics &amp; Governance</th>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science &amp; Technology</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.756374</td>\n",
       "      <td>0.756374</td>\n",
       "      <td>0.756374</td>\n",
       "      <td>0.756374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.755089</td>\n",
       "      <td>0.753963</td>\n",
       "      <td>0.751346</td>\n",
       "      <td>353.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.756843</td>\n",
       "      <td>0.756374</td>\n",
       "      <td>0.753396</td>\n",
       "      <td>353.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score     support\n",
       "Business & Economy      0.921053  0.875000  0.897436   40.000000\n",
       "Education & Career      0.717391  0.825000  0.767442   40.000000\n",
       "Entertainment           0.795455  0.897436  0.843373   39.000000\n",
       "Food & Health           0.900000  0.675000  0.771429   40.000000\n",
       "International           0.738095  0.775000  0.756098   40.000000\n",
       "Others                  0.444444  0.400000  0.421053   40.000000\n",
       "Politics & Governance   0.645161  0.588235  0.615385   34.000000\n",
       "Science & Technology    0.681818  0.750000  0.714286   40.000000\n",
       "Sports                  0.952381  1.000000  0.975610   40.000000\n",
       "accuracy                0.756374  0.756374  0.756374    0.756374\n",
       "macro avg               0.755089  0.753963  0.751346  353.000000\n",
       "weighted avg            0.756843  0.756374  0.753396  353.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(report).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal] *",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
